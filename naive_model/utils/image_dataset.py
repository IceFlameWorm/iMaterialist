import tensorflow as tf
from PIL import Image
import numpy as np
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '0,2'  # use gpu 1 to train

ROOT_PATH = '/media/data2/lzhang_data/dataset/iMaterial/'
TF_RECORDS_PATH = ROOT_PATH + 'tfrecords/'

image_size = 256
class_num = 128
image_croped_size = 224
data_augment_image_number = 8


def __image_parser(example_proto):
    features = {
        'label': tf.FixedLenFeature([], tf.int64),
        'img_raw': tf.FixedLenFeature([], tf.string),
    }
    parsed = tf.parse_single_example(example_proto, features)
    image = tf.decode_raw(parsed['img_raw'], tf.uint8)
    image = tf.reshape(image, [image_size, image_size, 3])
    # print(np.shape(image))
    label = tf.cast(parsed['label'], tf.int64)
    return image, label


# for each image, there will be 8 images generated by data augmentation
def __image_parser_data_augmentation(example_proto):
    features = {
        'label': tf.FixedLenFeature([], tf.int64),
        'img_raw': tf.FixedLenFeature([], tf.string),
    }
    parsed = tf.parse_single_example(example_proto, features)
    img = tf.decode_raw(parsed['img_raw'], tf.uint8)
    img = tf.reshape(img, [image_size, image_size, 3])

    # data argumentation
    imgs = []
    labels = []
    imgs.append(img)

    img_croped1 = tf.random_crop(img, size=[image_croped_size, image_croped_size, 3])
    img_pad1 = tf.image.pad_to_bounding_box(img_croped1, offset_height=0, offset_width=0, target_height=image_size,
                                            target_width=image_size)
    img_croped2 = tf.random_crop(img, size=[image_croped_size, image_croped_size, 3])
    img_pad2 = tf.image.pad_to_bounding_box(img_croped2, offset_height=0, offset_width=0, target_height=image_size,
                                            target_width=image_size)
    imgs.append(img_pad1)
    imgs.append(img_pad2)
    imgs.append(tf.image.random_flip_left_right(img))
    imgs.append(tf.image.random_hue(img, max_delta=0.05))
    imgs.append(tf.image.random_contrast(img, lower=0.3, upper=1.0))
    imgs.append(tf.image.random_brightness(img, max_delta=0.2))
    imgs.append(tf.image.random_saturation(img, lower=0.0, upper=2.0))
    img = tf.convert_to_tensor(imgs)
    label = tf.cast(parsed['label'], tf.int64)
    labels.append(label)
    labels = labels * data_augment_image_number
    label = tf.convert_to_tensor(labels)
    return img, label


def __get_batched_dataset(dataset_type, batch_size):
    dataset = tf.data.TFRecordDataset(TF_RECORDS_PATH + 'iMaterialist_' + dataset_type + '.tfrecords')
    print(TF_RECORDS_PATH + 'iMaterialist_' + dataset_type + '.tfrecords')

    if dataset_type is 'train':
        dataset = dataset.map(__image_parser_data_augmentation, 256)
        dataset = dataset.batch(int(batch_size / data_augment_image_number))
    else:
        dataset = dataset.map(__image_parser, 256)
        dataset = dataset.batch(batch_size)
    dataset = dataset.repeat()
    dataset = dataset.shuffle(buffer_size=1024, seed=1)

    itera = dataset.make_one_shot_iterator()
    image, label = itera.get_next()
    return image, label


def get_batched_validation_dataset(batch_size):
    return __get_batched_dataset(dataset_type='validation', batch_size=batch_size)


def get_batched_train_dataset(batch_size):
    return __get_batched_dataset(dataset_type='train', batch_size=batch_size)
